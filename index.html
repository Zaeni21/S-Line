<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Aura Tali Merah Menyatu</title>
  <style>
    body {
      margin: 0;
      background: #000;
      overflow: hidden;
    }
    #container {
      position: relative;
      width: 100vw;
      height: 100vh;
    }
    #video {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      z-index: 0;
    }
    canvas {
      position: absolute !important;
      top: 0;
      left: 0;
      z-index: 1;
      pointer-events: none;
    }
  </style>
</head>
<body>
  <div id="container">
    <video id="video" autoplay muted playsinline></video>
  </div>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.2/p5.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@0.0.3/dist/face-landmarks-detection.min.js"></script>

  <script>
    let video;
    let model;
    let head = null;

    async function setup() {
      const container = document.getElementById('container');
      createCanvas(windowWidth, windowHeight).parent(container);

      video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;

      await tf.setBackend('webgl');
      model = await faceLandmarksDetection.load(
        faceLandmarksDetection.SupportedPackages.mediapipeFacemesh
      );

      detectFace();
    }

    function draw() {
      clear(); // penting! biar canvas transparan
      if (head) {
        fill(255, 0, 0);
        noStroke();
        ellipse(head.x, head.y, 10, 10);

        stroke(255, 0, 0);
        strokeWeight(2);
        let total = 8;
        let spread = PI / 1.2;
        for (let i = 0; i < total; i++) {
          let angle = map(i, 0, total - 1, -spread / 2, spread / 2);
          let len = 80 + sin(frameCount * 0.1 + i) * 10;
          let x2 = head.x + len * cos(angle);
          let y2 = head.y - len * sin(angle);
          line(head.x, head.y, x2, y2);
        }
      }
    }

    async function detectFace() {
      if (!model || video.readyState !== 4) {
        setTimeout(detectFace, 100);
        return;
      }

      try {
        const predictions = await model.estimateFaces({ input: video });
        if (predictions.length > 0) {
          const nose = predictions[0].scaledMesh[10]; // dahi/atas hidung
          head = createVector(
            map(nose[0], 0, video.videoWidth, 0, width),
            map(nose[1], 0, video.videoHeight, 0, height)
          );
        } else {
          head = null;
        }
      } catch (err) {
        console.error("Face detection error:", err);
      }

      setTimeout(detectFace, 100);
    }

    function windowResized() {
      resizeCanvas(windowWidth, windowHeight);
    }
  </script>
</body>
</html>
